\relax 
\AC@reset@newl@bel
\newacro{mlp}[\AC@hyperlink{mlp}{MLP}]{Multi-Layer-Perceptron}
\newacro{cnn}[\AC@hyperlink{cnn}{CNN}]{Convolutional Neural Network}
\newacro{rnn}[\AC@hyperlink{rnn}{RNN}]{Recurrent Neural Network}
\newacro{vae}[\AC@hyperlink{vae}{VAE}]{Variational Auto-Encoder}
\newacro{gan}[\AC@hyperlink{gan}{GAN}]{Generative Adversarial Network}
\newacro{bn}[\AC@hyperlink{bn}{BN}]{Batch Normalization}
\newacro{ln}[\AC@hyperlink{ln}{LN}]{Layer Normalization}
\newacro{ml}[\AC@hyperlink{ml}{ML}]{Machine Learning}
\newacro{dl}[\AC@hyperlink{dl}{DL}]{Deep Learning}
\newacro{hpo}[\AC@hyperlink{hpo}{HPO}]{Hyperparameter Optimization}
\newacro{bptt}[\AC@hyperlink{bptt}{BPTT}]{backpropagation through time}
\newacro{mse}[\AC@hyperlink{mse}{MSE}]{Mean Squared Error}
\newacro{kl}[\AC@hyperlink{kl}{KL}]{Kullback-Leibler}
\newacro{mle}[\AC@hyperlink{mle}{MLE}]{Maximum Likelihood Estimation}
\newacro{relu}[\AC@hyperlink{relu}{ReLU}]{Rectified Linear Unit}
\newacro{sgd}[\AC@hyperlink{sgd}{SGD}]{Stochastic Gradient Descent}
\newacro{lstm}[\AC@hyperlink{lstm}{LSTM}]{Long Short-Term Memory}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{}\protected@file@percent }
\AC@undonewlabel{acro:dl}
\newlabel{acro:dl}{{1.1}{1}{Representation Learning vs. \ac {dl}}{}{}}
\acronymused{dl}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Representation Learning vs. \ac {dl}}{1}{}\protected@file@percent }
\acronymused{dl}
\AC@undonewlabel{acro:ml}
\newlabel{acro:ml}{{1.2}{1}{\ac {ml} Concepts}{}{}}
\acronymused{ml}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}\ac {ml} Concepts}{1}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.1}Linear Regression}{1}{}\protected@file@percent }
\AC@undonewlabel{acro:mse}
\newlabel{acro:mse}{{1.2.1}{1}{Linear Regression}{}{}}
\acronymused{mse}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Logistic Regression}{1}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.3.1}Overfitting and Underfitting}{2}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.3.2}Cross-Validation}{2}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4}Basics of Neural Networks}{2}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.4.1}Types of Tasks}{2}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.4.2}Single Neurons}{2}{}\protected@file@percent }
\AC@undonewlabel{acro:mlp}
\newlabel{acro:mlp}{{2}{2}{\acp {mlp}}{}{}}
\acronymused{mlp}
\@writefile{toc}{\contentsline {section}{\numberline {2}\acp {mlp}}{2}{}\protected@file@percent }
\AC@undonewlabel{acro:kl}
\newlabel{acro:kl}{{2.1}{2}{Entropy \& \ac {kl}-Divergence}{}{}}
\acronymused{kl}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Entropy \& \ac {kl}-Divergence}{2}{}\protected@file@percent }
\acronymused{kl}
\acronymused{kl}
\AC@undonewlabel{acro:mle}
\newlabel{acro:mle}{{2.2}{3}{\ac {mle}}{}{}}
\acronymused{mle}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}\ac {mle}}{3}{}\protected@file@percent }
\acronymused{mle}
\acronymused{mlp}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}\acl {mlp}}{3}{}\protected@file@percent }
\acronymused{mlp}
\AC@undonewlabel{acro:relu}
\newlabel{acro:relu}{{2}{4}{\acl {mlp}}{}{}}
\acronymused{relu}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Activation Functions}{4}{}\protected@file@percent }
\acronymused{relu}
\@writefile{toc}{\contentsline {section}{\numberline {3}Backpropagation}{4}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Derivations of Activations}{5}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Backpropagation in Neural Networks}{5}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Optimization}{6}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Optimization vs. Learning}{6}{}\protected@file@percent }
\acronymused{dl}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Gradient-Based Optimization}{6}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Ill-Conditioning}{6}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Challenges of Optimization}{7}{}\protected@file@percent }
\AC@undonewlabel{acro:rnn}
\newlabel{acro:rnn}{{1}{7}{Challenges of Optimization}{}{}}
\acronymused{rnn}
\AC@undonewlabel{acro:sgd}
\newlabel{acro:sgd}{{4.5}{7}{\ac {sgd}}{}{}}
\acronymused{sgd}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5}\ac {sgd}}{7}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6}Learning Rate Schedules}{8}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.7}SGD with Momentum}{8}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.8}Adaptive Gradient Algorithms}{8}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}Regularization}{9}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Small Weights (Shrinkage Methods)}{9}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Decoupled Weight Decay}{10}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Parameter Sharing/Tying}{10}{}\protected@file@percent }
\AC@undonewlabel{acro:cnn}
\newlabel{acro:cnn}{{5.3}{10}{Parameter Sharing/Tying}{}{}}
\acronymused{cnn}
\acronymused{rnn}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4}Dropout}{10}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5}Data Augmentation}{10}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.6}Noise Robustness}{11}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.7}Adversarial Training}{11}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.8}Ensemble Methods}{11}{}\protected@file@percent }
\acronymused{cnn}
\@writefile{toc}{\contentsline {section}{\numberline {6}\acp {cnn}}{12}{}\protected@file@percent }
\acronymused{cnn}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}More Properties of Convolutions}{12}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Miscellaneous Convolutions}{12}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3}Pooling}{13}{}\protected@file@percent }
\acronymused{rnn}
\@writefile{toc}{\contentsline {section}{\numberline {7}\acp {rnn}}{13}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1}General}{13}{}\protected@file@percent }
\acronymused{rnn}
\acronymused{rnn}
\acronymused{rnn}
\acronymused{rnn}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2}Design Patterns}{13}{}\protected@file@percent }
\acronymused{rnn}
\acronymused{rnn}
\AC@undonewlabel{acro:bptt}
\newlabel{acro:bptt}{{7.2}{13}{Design Patterns}{}{}}
\acronymused{bptt}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.3}Miscellaneous Architectures}{14}{}\protected@file@percent }
\acronymused{bptt}
\acronymused{rnn}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.4}Problems during Training}{14}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.5}Truncated BPTT}{14}{}\protected@file@percent }
\AC@undonewlabel{acro:lstm}
\newlabel{acro:lstm}{{7.6}{14}{\ac {lstm}}{}{}}
\acronymused{lstm}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.6}\ac {lstm}}{14}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {8}Attention \& Transformers}{15}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.1}Types of Attention}{15}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.2}RNNs with Attention}{15}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.3}Transformers}{15}{}\protected@file@percent }
\acronymused{rnn}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.4}Encoder: Flow of Vectors}{16}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.5}Self-Attention}{16}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.6}Multi-Head Self-Attention}{16}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.7}Transformer: Encoder and Decoder}{16}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.8}Limitations of Attention}{17}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {9}Methodology}{17}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {9.1}Batch Normalization}{17}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {9.2}Layer Normalization}{18}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {9.3}Transfer Learning}{18}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {9.4}Parameter Initialization}{18}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {9.5}CNN Architectures}{19}{}\protected@file@percent }
\AC@undonewlabel{acro:vae}
\newlabel{acro:vae}{{10}{19}{\acp {vae}}{}{}}
\acronymused{vae}
\@writefile{toc}{\contentsline {section}{\numberline {10}\acp {vae}}{19}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {10.1}Autoencoders}{19}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {10.2}Regularized Autoencoders}{19}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {10.3}Sparse Autoencoders}{19}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {10.4}Denoising Autoencoders}{20}{}\protected@file@percent }
\acronymused{vae}
\@writefile{toc}{\contentsline {subsection}{\numberline {10.5}\acp {vae}}{20}{}\protected@file@percent }
\acronymused{vae}
\AC@undonewlabel{acro:gan}
\newlabel{acro:gan}{{11}{21}{\acp {gan}}{}{}}
\acronymused{gan}
\@writefile{toc}{\contentsline {section}{\numberline {11}\acp {gan}}{21}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {11.1}Diffusion Models}{21}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {12}Uncertainty Estimation}{22}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {12.1}DNGO Model}{22}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {12.2}Bayesian Neural Networks}{22}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {12.3}Variational Inference}{23}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {12.4}Markov-Chain-Monte-Carlo (MCMC) Method}{23}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {12.5}Prior-Fitted Networks (PFNs)}{23}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {12.6}Output Ensembling}{23}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {12.7}The Estimation of Parametric Models}{24}{}\protected@file@percent }
\AC@undonewlabel{acro:hpo}
\newlabel{acro:hpo}{{13}{24}{AutoML / \ac {hpo}}{}{}}
\acronymused{hpo}
\@writefile{toc}{\contentsline {section}{\numberline {13}AutoML / \ac {hpo}}{24}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {13.1}Practical Tips}{25}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {13.2}Black-Box Optimization}{25}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {13.3}Bayesian Optimization}{25}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {13.4}Population-based Methods}{25}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {13.5}HPO Speedup Techniques}{25}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {13.6}Combining User Beliefs with Bayesian Optimization}{26}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {13.7}Hyperparameter Gradient Descent}{26}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {13.8}Neural Architecture Search (NAS)}{26}{}\protected@file@percent }
\gdef \@abspage@last{26}
